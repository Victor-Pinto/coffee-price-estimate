{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Web Scrapping to CoE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(1, '../shared')\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from time import sleep\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import os.path\n",
    "from os import path\n",
    "\n",
    "from utils import verbosity\n",
    "\n",
    "from typing_extensions import List, Dict\n",
    "\n",
    "import pandas as pd\n",
    "df = pd.DataFrame()\n",
    "\n",
    "import math\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define WebScrapping atributes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "verbosity(msg=f'getting_link',\n",
    "            tl=1)\n",
    "\n",
    "auction_link = 'https://allianceforcoffeeexcellence.org/competition-auction-results/'\n",
    "\n",
    "is_verbosity = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define other classess"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Attributes dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AttributesDictionary:\n",
    "    \n",
    "    \n",
    "    def __init__(self):\n",
    "        self.dict_auction_translator = {\n",
    "            'Country': [''],\n",
    "            'Rank': ['RANK', 'Ranking', 'LOT NUMBER', 'Rank', 'LOT #', 'Lot #', 'Lot Number', 'LOT NO.', 'Lot number'],\n",
    "            'Score': ['SCORE', 'Score'],\n",
    "            'Farm':['FARM', 'Farm', 'Farm / CWS', 'Winning Farm / CWS', 'FARM NAME', 'Farm Name', 'FARM / CWS', 'Nome', \n",
    "                    'FARM/CWS', 'WINNING FARM / CWS', 'FARM / CWS'],\n",
    "            'Url_farm':[''],\n",
    "            'Farmer':['FARMER', 'Farmer / Representative', 'PRODUCER', 'Farmer', 'FARMER / REPRESENTATIVE', \n",
    "                      'Producer', 'Title Farmer / Organization', 'Farmer Name'],\n",
    "            'Region':['REGION', 'Region'],\n",
    "            'Weigth_(Kg)':['WEIGHT (KG)', 'Weight (kg)', 'Weight (KG)', 'WEIGHT (kg)', 'Weight', 'WEIGHT (Kg)', \n",
    "                           'Weight (Kg)', 'WEIGHTS (Kg)', 'Estimated Weight (kg)', 'WEIGTH (Kg)', 'Auction Lot Size (kg)',\n",
    "                           ],\n",
    "            'Weigth_(Lb)':['Weight – lbs', 'Pounds', 'Weight – Lbs', 'Weight (lbs)', 'Weight (lbs.)', 'Weight (Lbs)', \n",
    "                           'WEIGHT (lb)', 'POUNDS (lb)', 'Weight(Lb)', 'Weight (lb)', 'Weight(Lbs)'],\n",
    "            'Variety':['VARIETY', 'Variety', 'Variedad', 'Variety', 'Variety '],\n",
    "            'Processing':['PROCESS', 'Process', 'Processing', 'Process, Variety', 'PROCESSING', ' Variety/Processing',\n",
    "                          'Proceso', 'Processing system', 'Processing System'],\n",
    "            'High_Bid':['High Bid', 'HIGH BID', ' Price per lb', 'Price per lb', '\\xa0Price per lb', '&nbsp;Price per lb', \n",
    "                        'Bid ($/lb)', 'Bid', ' FINAL BID ($/lb)', 'HIGHEST BID', 'Hight Bid', 'High Bid ($/lb)', \n",
    "                        'Total value', 'PRICE PER (lb)', 'HighBid', 'High bid'],\n",
    "            'High_Bidders':['High Bidder(s)', 'HIGH BIDDER(S)', 'Winner', 'High bidder(s)', 'High bidder', 'High bidders' ],\n",
    "            'Origin_Bidder':['Origin', 'Buyer’s Location', 'COUNTRY', 'Country', 'Country of Origin'],\n",
    "            'Total_Value':['Total Value', 'TOTAL VALUE', 'Total Price', ' Total Value', 'Total Value ($)', 'TOTAL PRICE',\n",
    "                           ' Total Price', ' Total Value'],\n",
    "            'Total_Comission':['TOTAL COMISSION', 'Commissions', 'Auction Commission', 'Commission', 'Comissions', \n",
    "                               'COMMISSION', ' COMISSION', 'Total Commissions', 'AUCTION COMMISSION', ' Commission'],\n",
    "            'Company_Name':['Company Name'],\n",
    "            'Size_30Kg_boxes':['Size', 'Lot Size', 'Size (30kg Boxes)', 'SIZE', 'Boxes', 'LOT SIZE', \n",
    "                               'Size (30kg boxes)'],\n",
    "            'Altitude':['ALTITUDE (masl)', 'ALTITUDE (m)', 'Altitude'],\n",
    "            'History':[''],\n",
    "            'Enviromental_Care':[''],\n",
    "            'Coffee_Processing_Information':[''],\n",
    "            'Annual_Production':[''],\n",
    "            'Annual_Precipitation':[''],\n",
    "            'Shade_Grown_Type':[''],\n",
    "            'Water_Source':[''],\n",
    "            'Coffee_Growing_Area':['Coffee Growing Area ', 'Coffee Growing Area'],\n",
    "            'Aroma_Flavor': ['Aroma/Flavor', 'Aroma / Flavor'],\n",
    "            'Acidity': ['Acidity'],\n",
    "            'Overall': ['Overall', 'Coffee Characteristics'],\n",
    "            'Other': ['Other'],\n",
    "            'Farm_Size': ['Farm Size'],\n",
    "            'Auction_Lot_Size': ['Auction Lot Size (lbs.)'],\n",
    "            'Auction_Lot_Size(Kg)': ['Auction Lot Size (kg)'],\n",
    "            'Certifications': ['Certifications'],\n",
    "            'City': ['City'],\n",
    "\n",
    "        }\n",
    "\n",
    "    def translate_attribute(self, value_attribute):\n",
    "        name_attribute = ''\n",
    "\n",
    "        for item in self.dict_auction_translator.items():\n",
    "            if value_attribute in item[1]:\n",
    "            # for attribute in item[1]:\n",
    "            #     if attribute == value_attribute:\n",
    "                name_attribute = item[0]\n",
    "                \n",
    "                return name_attribute\n",
    "        if name_attribute=='':\n",
    "            verbosity(f\"Title {value_attribute} not found; it will be added:\", tl=5)            \n",
    "            self.dict_auction_translator[value_attribute]=[value_attribute]\n",
    "            # return value_attribute\n",
    "                    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Other classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_number_in_string_array(array):\n",
    "    for value in array:\n",
    "        if value.isdigit():\n",
    "            return value\n",
    "\n",
    "class CharProcessing:\n",
    "    \n",
    "    @staticmethod\n",
    "    def get_country_name(auction_link):\n",
    "        auction_link=auction_link[:(len(auction_link)-1)]\n",
    "        array_auction_split = auction_link.split('/')\n",
    "        return array_auction_split[(len(array_auction_split))-1]\n",
    "        \n",
    "class SearchOperations:\n",
    "    \n",
    "    @staticmethod\n",
    "    def get_country_by_name(array_countries, name):\n",
    "        '''Returned argument is the country and link auction'''\n",
    "        for country in array_countries:\n",
    "            if(country['name']==name):\n",
    "                return country\n",
    "\n",
    "\n",
    "class SaveOperations:\n",
    "    def __init__(self):\n",
    "        pass\n",
    "    \n",
    "    \n",
    "    def file_exist(self, file_name):\n",
    "        \n",
    "        return path.exists(f'../static/{file_name}')\n",
    "    \n",
    "    def save_html_page(self, html_code, file_name):\n",
    "        verbosity(msg=f'enter in save_html_page function',\n",
    "                    tl=1)\n",
    "        verbosity(msg=f'checking if the file exist',\n",
    "                    tl=2)\n",
    "        if(self.file_exist(file_name)):\n",
    "            verbosity(msg=f'the file exist',\n",
    "                        tl=2)\n",
    "            verbosity(msg=f'saving html page',\n",
    "                        tl= 3)\n",
    "            f = open(f'../static/{file_name}','w')\n",
    "            f.write(html_code)\n",
    "            f.close()\n",
    "        else:\n",
    "            verbosity(msg=f\"the file doesn't exist\",\n",
    "                        tl=2)\n",
    "            verbosity(msg=f\"creating file\",\n",
    "                        tl=3)\n",
    "            f = open(f'../static/{file_name}', \"x\")\n",
    "            verbosity(msg=f\"saving html page\",\n",
    "                        tl=3)\n",
    "            f.write(html_code)\n",
    "            f.close()\n",
    "        verbosity(msg=f'out from save_html_page function',\n",
    "                    tl=1)\n",
    "\n",
    "class Page:\n",
    "    \n",
    "    \n",
    "    def __init__(self, root_link:str):\n",
    "        verbosity(msg=f'Page class was initialized with root_link: {root_link}',\n",
    "                    tl=1)\n",
    "        self.root_link = root_link\n",
    "        is_url = not(self.is_nan(root_link))\n",
    "        if is_url:\n",
    "            self.web_content = self.get_web_content()\n",
    "            self.found_404 = self.find_404()\n",
    "            self.attributes_dictionary = AttributesDictionary()\n",
    "        else:\n",
    "            self.found_404 = True\n",
    "            self.web_content=False\n",
    "\n",
    "    def is_nan(self, value):\n",
    "        if(type(value)==float):\n",
    "            if math.isnan(value):\n",
    "                return True\n",
    "            \n",
    "        return False\n",
    "        \n",
    "    def aux_found_404(self, value):\n",
    "        verbosity(value)\n",
    "        if value == '404':\n",
    "            raise ValueError('Error 404 in web page')\n",
    "\n",
    "\n",
    "    def find_404(self, tl_ini=5):\n",
    "        web_b_list = self.get_content_by_html_tags(self.web_content, 'b')\n",
    "        try:\n",
    "            [self.aux_found_404(web_b.text) for web_b in web_b_list]\n",
    "        except ValueError as e:\n",
    "            verbosity(f\"Value Error: {e}\", level='error', tl=tl_ini)\n",
    "            return True\n",
    "        return False\n",
    "\n",
    "        \n",
    "    def get_web_content(self, tl=2):\n",
    "        ''' returned the web content of a link with Beautiful Soup '''\n",
    "        verbosity(msg=f'getting web content', \n",
    "                    verb=is_verbosity, tl=tl)\n",
    "        sleep(0.5)\n",
    "        verbosity(msg=f'request page from link',\n",
    "                    verb=is_verbosity, tl= tl+1)\n",
    "        try:\n",
    "            response = requests.get(self.root_link)\n",
    "            verbosity(msg=f'Success request',\n",
    "                        verb=is_verbosity, tl= tl+2)\n",
    "        except Exception as e:\n",
    "            verbosity(msg = f'error: {e}',\n",
    "                    level='error',\tverb=is_verbosity, tl= tl+1)\n",
    "            return False\n",
    "            \n",
    "        verbosity(msg=f'returning content',\n",
    "                    verb=is_verbosity, tl= tl+2)\n",
    "        \n",
    "        web_content = BeautifulSoup(response.content, 'html.parser')\n",
    "        \n",
    "        return web_content\n",
    "    \n",
    "    def get_content_by_html_tags(self, beuty_object, html_tag):\n",
    "        ''' get the web content of beautiful object by html tag '''\n",
    "        return beuty_object.find_all(html_tag)\n",
    "    \n",
    "    \n",
    "    def get_content_by_class(self,  beuty_object, class_name,):\n",
    "        ''' get the web content of beautiful object by class '''\n",
    "        return beuty_object.find_all(class_=class_name)\n",
    "    \n",
    "       \n",
    "    def get_content_by_html_attr(self,  beuty_object, attribute_name, attribute_value):\n",
    "        ''' get the web content of beautiful object by attribute '''\n",
    "        return beuty_object.find_all(attrs={attribute_name : attribute_value})\n",
    "    \n",
    "    def get_p_text_from_id(self, id_value, tl_ini = 5):\n",
    "        try:\n",
    "            value = self.get_content_by_html_attr(self.web_content, 'id', id_value)[0]\n",
    "            value = self.get_content_by_html_tags(value, 'p')[0].text\n",
    "        except IndexError as e:\n",
    "            verbosity(f\"Value not found with id: {id_value}\", level='error', tl=tl_ini)\n",
    "            value = ''\n",
    "\n",
    "        return value\n",
    "    \n",
    "    def concat_elements_from_result(self, list):\n",
    "        text = \"\"\n",
    "        for value in list:\n",
    "            text = text + \"\\n\" + value.text\n",
    "        return text\n",
    "\n",
    "\n",
    "        \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define WebScrapping classess"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Class to Home Page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MainPage (Page):\n",
    "    \n",
    "        \n",
    "    def get_auction_links(self, web_content_main, id_main_menu):\n",
    "        '''\n",
    "        Summary: \n",
    "            get the links of auctions in main page\n",
    "        \n",
    "        Parameters:\n",
    "            web_content_main: content of main page\n",
    "            id_main_menu: id to search all links in main menu\n",
    "            \n",
    "        Returns:\n",
    "            list with the auctions links\n",
    "        \n",
    "        '''\n",
    "        links = web_content_main.find_all(id=id_main_menu)[0].find_all('a')\n",
    "        array_auctions_links = []\n",
    "        \n",
    "        index = 0\n",
    "        for link in links[:(len(links)-1)]:\n",
    "            link_href = str(link.get('href'))\n",
    "            if(link_href!='#' and link_href != 'None'):\n",
    "                array_auctions_links.append(\n",
    "                    {\n",
    "                        'name': CharProcessing.get_country_name(link_href),\n",
    "                        'link': link_href\n",
    "                    }\n",
    "                )\n",
    "                                \n",
    "                \n",
    "                # array_auctions_links['name'].append(CharProcessing.get_country_name(link_href))\n",
    "                # array_auctions_links['link'].append(link_href)\n",
    "        return array_auctions_links\n",
    "                \n",
    "                # index += 1\n",
    "            \n",
    "        \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Auction Data Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class Auction:\n",
    "    def __init__(self):\n",
    "        self.dict_auction = {\n",
    "            'Year': '',\n",
    "            'Country': '',\n",
    "            'Rank': '',\n",
    "            'Score': '',\n",
    "            'Farm':'',\n",
    "            'Url_farm':'',\n",
    "            'Farmer':'',\n",
    "            'Region':'',\n",
    "            'Weigth_(Kg)':'',\n",
    "            'Weigth_(Lb)':'',\n",
    "            'Variety':'',\n",
    "            'Processing':'',\n",
    "            'High_Bid':'',\n",
    "            'High_Bidders':'',\n",
    "            'Origin_Bidder':'',\n",
    "            'Total_Value':'',\n",
    "            'Total_Comission':'',\n",
    "            'Company_Name':'',\n",
    "            'Size_30Kg_boxes':'',\n",
    "            'Altitude':'',\n",
    "            'History':'',\n",
    "            'Enviromental_Care':'',\n",
    "            'Coffee_Processing_Information':'',\n",
    "            'Annual_Production':'',\n",
    "            'Annual_Precipitation':'',\n",
    "            'Shade_Grown_Type':'',\n",
    "            'Water_Source':'',\n",
    "            'Coffee_Growing_Area':'',\n",
    "            'Aroma_Flavor':'',\n",
    "            'Acidity':'',\n",
    "            'Overall':'',\n",
    "            'Other':'',\n",
    "            'Farm_Size':'',\n",
    "            'Auction_Lot_Size':'',\n",
    "            'Auction_Lot_Size(Kg)':'',\n",
    "            'Certifications':'',\n",
    "            'City':'',\n",
    "\n",
    "        }\n",
    "\n",
    "        \n",
    "    def get_dict_auction(self):\n",
    "        return self.dict_auction\n",
    "    \n",
    "    def set_dict_auction(self, dict_auction):\n",
    "        self.dict_auction = dict_auction\n",
    "    \n",
    "        \n",
    "    \n",
    "    def __str__(self):\n",
    "        string = (\"Country: \" +self.dict_auction['Country'] + \n",
    "                    \"\\n\" + \"Rank: \" +self.dict_auction['Rank'] + \n",
    "                    \"\\n\" + \"Score: \" + self.dict_auction['Score'] + \n",
    "                    \"\\n\" + \"Farm: \" + self.dict_auction['Farm'] + \n",
    "                    \"\\n\" + \"Url_farm: \" + self.dict_auction['Url_farm'] + \n",
    "                    \"\\n\" + \"Farmer: \" + self.dict_auction['Farmer'] + \n",
    "                    \"\\n\" + \"Region: \" + self.dict_auction['Region'] + \n",
    "                    \"\\n\" + \"Weigth_(Kg): \" + self.dict_auction['Weigth_(Kg)'] + \n",
    "                    \"\\n\" + \"Weigth_(Lb): \" + self.dict_auction['Weigth_(Lb)'] + \n",
    "                    \"\\n\" + \"Variety: \" + self.dict_auction['Variety'] + \n",
    "                    \"\\n\" + \"Process: \" + self.dict_auction['Process'] + \n",
    "                    \"\\n\" + \"High_Bid: \" + self.dict_auction['High_Bid'] + \n",
    "                    \"\\n\" + \"Total_Value: \" + self.dict_auction['Total_Value'] + \n",
    "                    \"\\n\" + \"Company_Name: \" + self.dict_auction['Company_Name'] + \n",
    "                    \"\\n\" + \"Total_Comission: \" + self.dict_auction['Total_Comission'] + \n",
    "                    \"\\n\")\n",
    "        return string\n",
    "                \n",
    "        \n",
    "class AuctionData:\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.array_auctions = []\n",
    "        self.auctions_number = 0\n",
    "        self.tl = 3\n",
    "    \n",
    "    \n",
    "    def set_auctions_number(self, auctions_number):\n",
    "        self.auctions_number = auctions_number\n",
    "    \n",
    "    \n",
    "    def get_auctions_number(self):\n",
    "        return self.auctions_number \n",
    "    \n",
    "    def compare_auction_index(self, auction, rank):\n",
    "        if auction.get_dict_auction()['Rank'].lower() == rank.lower():\n",
    "            return True\n",
    "        else:\n",
    "            return False\n",
    "\n",
    "    \n",
    "    def get_dict_auction_index_by_rank(self, rank):\n",
    "        try:\n",
    "            dict_auction_index = [self.compare_auction_index(auction, rank) for auction in self.array_auctions].index(True)\n",
    "            return dict_auction_index\n",
    "        \n",
    "        except ValueError as e:\n",
    "            # verbosity(f'Value Error in get_dict_auction_index_by_rank function: {e} in rank {rank} ', level='error', tl=self.tl)\n",
    "            return 'False'\n",
    "        \n",
    "        except AttributeError as e:\n",
    "            verbosity(f'Attribute Error in get_dict_auction_index_by_rank function: {e}', level='error', tl=3)\n",
    "            return 'False'\n",
    "    \n",
    "    \n",
    "    \n",
    "    def refactor_array_auctions(self):\n",
    "        # print(self.array_auctions)\n",
    "        array_auctions_complete = []\n",
    "        try:\n",
    "            array_auctions_complete = [auction.get_dict_auction() for auction in self.array_auctions]\n",
    "        except AttributeError:\n",
    "            verbosity(msg=f'error detected in Auction object', level='Error', tl=1)\n",
    "        \n",
    "        return(array_auctions_complete)\n",
    "        # print(self.array_auctions_complete)\n",
    "    \n",
    "    def get_data_titles(self):\n",
    "        dict_auction = self.array_auctions[0].get_dict_auction()\n",
    "        verbosity(msg=f'getting title_auctions',\n",
    "                    tl=1)\n",
    "        array_titles = [title_auction for title_auction in dict_auction.keys()]\n",
    "        verbosity(msg=f'getting title_auctions - Success!',\n",
    "                    tl=1)\n",
    "        return array_titles\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Class to Auction Results Page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class AuctionResultsPage(Page):\n",
    "    \n",
    "    def __init__(self, dict_page_country:Dict):\n",
    "        self.root_link = dict_page_country['link']\n",
    "        super().__init__(self.root_link)\n",
    "        array_name_page = dict_page_country['name'].split('-')\n",
    "        self.country = dict_page_country['name']\n",
    "        self.year = find_number_in_string_array(array_name_page)\n",
    "        verbosity(msg=f'Page class was initialized with. \\n root_link: {self.root_link} \\n country: {self.country} \\n year: {self.year}',\n",
    "                    verb=is_verbosity, tl=1)\n",
    "    \n",
    "    def get_table_titles (self, array_td, attributes_dictionary):\n",
    "        array_titles = []\n",
    "        for td in array_td:\n",
    "            array_titles.append(attributes_dictionary.translate_attribute(td.text))\n",
    "        return array_titles\n",
    "    \n",
    "    def get_auction_data(self, web_content_main, tl=3):\n",
    "        if self.web_content==False:\n",
    "            pass\n",
    "            \n",
    "        verbosity(msg=f'getting auction data',\n",
    "            verb=is_verbosity, tl=tl)\n",
    "        auction_data = AuctionData()\n",
    "        attributes_dictionary = AttributesDictionary()\n",
    "        array_table = self.get_content_by_html_tags(web_content_main, 'table')\n",
    "\n",
    "        for table_data in array_table:\n",
    "            try:\n",
    "                array_table_body = self.get_content_by_html_tags(table_data, 'tbody')[0]\n",
    "            except IndexError:\n",
    "                continue\n",
    "            array_table_head = self.get_content_by_html_tags(table_data, 'thead')\n",
    "            array_tr = self.get_content_by_html_tags(array_table_body, 'tr')\n",
    "            title_in_initial_tr = False\n",
    "            array_titles = []\n",
    "            \n",
    "\n",
    "            if len(array_table_head)!=0:\n",
    "                    array_th = self.get_content_by_html_tags(array_table_head[0], 'th')\n",
    "                    array_titles = self.get_table_titles(array_th, attributes_dictionary)\n",
    "            else:\n",
    "                array_td = self.get_content_by_html_tags(array_tr[0], 'td')\n",
    "                array_titles = self.get_table_titles(array_td, attributes_dictionary)\n",
    "                title_in_initial_tr = True\n",
    "\n",
    "            for tr in array_tr:\n",
    "                array_td = self.get_content_by_html_tags(tr, 'td')\n",
    "                is_fake = False\n",
    "                auction_index = 'False'\n",
    "                auction = Auction()\n",
    "                if title_in_initial_tr:\n",
    "                    title_in_initial_tr = False\n",
    "                \n",
    "                else:\n",
    "                    for td, table_title in zip(array_td, array_titles):\n",
    "                        if table_title == 'Farm':\n",
    "                            a_tag = td.find('a', href=True) #self.get_content_by_html_tags(td, 'a')[0]\n",
    "                            if(a_tag != None):\n",
    "                                auction.dict_auction['Url_farm'] = a_tag['href']\n",
    "                            auction.dict_auction[table_title] = td.text\n",
    "                        else:\n",
    "                            if table_title == 'Rank':\n",
    "                                auction_index = auction_data.get_dict_auction_index_by_rank(td.text)    \n",
    "                                \n",
    "                                if (str(td.text)==''):\n",
    "                                    is_fake = True\n",
    "                                auction.dict_auction[table_title] = (td.text.lower())\n",
    "                            \n",
    "                            else:\n",
    "                                auction.dict_auction[table_title] = td.text\n",
    "                            \n",
    "                            \n",
    "                    if(not(is_fake)):\n",
    "                        if(auction_index!='False'):\n",
    "                            for key, value in auction.get_dict_auction().items():\n",
    "                                if(value!=''):\n",
    "                                    auction_data.array_auctions[auction_index].get_dict_auction()[key] = value\n",
    "                                                                \n",
    "                            # auction.set_dict_auction(auction_data.array_auctions[auction_index].get_dict_auction() | auction.get_dict_auction())\n",
    "                        else:\n",
    "                            auction.dict_auction['Country'] = self.country\n",
    "                            auction.dict_auction['Year'] = self.year\n",
    "                            try:\n",
    "                                auction.get_dict_auction()['Rank'][0].isnumeric()\n",
    "                                auction_data.array_auctions.append(auction)\n",
    "                            except:\n",
    "                                pass\n",
    "                        \n",
    "        return auction_data                      \n",
    "            \n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Main Program to extract auctions data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data_of_countries(country_to_find_data=''):\n",
    "    '''\n",
    "    Summary:\n",
    "        get all data of country auction tables\n",
    "\n",
    "    Parameters: \n",
    "        country_to_find_data: name of the country and year ie. brazil-2023, brazil\n",
    "\n",
    "    '''\n",
    "    country_to_find_data = '' # if empty, then search all ie. 'brazil-2023'\n",
    "    auction_file_name = 'Auctions.xlsx'\n",
    "    ## Web Scrapping\n",
    "    auction = Auction()\n",
    "    mainPage = MainPage(auction_link)\n",
    "    web_content_main = mainPage.get_web_content()   \n",
    "    array_auctions_links = mainPage.get_auction_links(web_content_main, 'menu-coe-country-programs-menu')\n",
    "    df_auctions = pd.DataFrame(columns=auction.dict_auction.keys())\n",
    "    if country_to_find_data:\n",
    "        array_auctions_links = [auction for auction in array_auctions_links if country_to_find_data in auction['name'] ]\n",
    "        auction_file_name = f\"Auctions-{country_to_find_data}.xlsx\"\n",
    "\n",
    "    else: \n",
    "        array_auctions_links = [auction for auction in array_auctions_links ]\n",
    "    for country in array_auctions_links:\n",
    "        auction_page = AuctionResultsPage(country)\n",
    "        web_content_auction_page = auction_page.get_web_content()\n",
    "        auction_data = auction_page.get_auction_data(web_content_auction_page)\n",
    "        array_dict_auctions = auction_data.refactor_array_auctions()\n",
    "        df = pd.DataFrame(array_dict_auctions)\n",
    "        df_auctions = pd.concat([df_auctions, df], ignore_index=True)\n",
    "        # verbosity(msg=f\"df_auctions = \\n {df_auctions.tail()}\", tl=1)\n",
    "\n",
    "    df_auctions.to_excel(f\"../auctions_download/{auction_file_name}\")\n",
    "\n",
    "# get_data_of_countries()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Main Program to extract deep auctions data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Deep Auction Page Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DeepAuctionPage(Page):\n",
    "\n",
    "    def __init__(self, df_auction_row):\n",
    "        root_link = df_auction_row['Url_farm']\n",
    "        super().__init__(root_link)\n",
    "        self.auction_data = {\n",
    "            'History':'',\n",
    "            'Enviromental_Care':'',\n",
    "            'Coffee_Processing_Information':'',\n",
    "            'Annual_Production':'',\n",
    "            'Annual_Precipitation':'',\n",
    "            'Shade_Grown_Type':'',\n",
    "            'Water_Source':'',\n",
    "            'Coffee_Growing_Area':'',\n",
    "            'Aroma_Flavor':'',\n",
    "            'Acidity':'',\n",
    "            'Overall':'',\n",
    "            'Other':'',\n",
    "            'Farm_Size':'',\n",
    "            'Auction_Lot_Size':'',\n",
    "            'Auction_Lot_Size(Kg)':'',\n",
    "            'Certifications':'',\n",
    "            'City':'',\n",
    "        }\n",
    "        self.df_auction_row = df_auction_row\n",
    "\n",
    "\n",
    "\n",
    "    def save_value(self, key_dict, value, tl_ini=3):\n",
    "\n",
    "        try:\n",
    "            if self.is_nan(self.df_auction_row[key_dict]):\n",
    "                if value!='':\n",
    "                    self.auction_data[key_dict] = value\n",
    "                \n",
    "        except KeyError as e:\n",
    "            verbosity(f\"Key dict:-{key_dict}-not found\", tl=tl_ini)\n",
    "\n",
    "    def get_description_from_auction(self):\n",
    "        description_value = self.get_p_text_from_id('listing-description')\n",
    "        data_table = self.get_content_by_html_attr(self.web_content, 'id', 'listing-details')\n",
    "\n",
    "        if(description_value=='' and len(data_table)==0):\n",
    "            web_description_div=self.get_content_by_class(self.web_content, 'block-field-job_description')\n",
    "            if len(web_description_div)>=1:\n",
    "                web_description_div=web_description_div[0]\n",
    "                web_description_body=self.get_content_by_class(web_description_div, 'pf-body')[0]\n",
    "                web_description_paragraph_list=self.get_content_by_html_tags(web_description_body, 'p')\n",
    "                description_value = self.concat_elements_from_result(web_description_paragraph_list)\n",
    "        self.save_value('History', description_value)\n",
    "\n",
    "    def get_data_from_horizontal_table(self):\n",
    "        data_table = self.get_content_by_html_attr(self.web_content, 'id', 'listing-details')[0]\n",
    "        data_table_title = self.get_content_by_html_tags(data_table, 'th')\n",
    "        data_table_value = self.get_content_by_html_tags(data_table, 'td')\n",
    "        for title, value in zip (data_table_title, data_table_value):\n",
    "            key_dict = self.attributes_dictionary.translate_attribute(title.text)\n",
    "            if(key_dict):\n",
    "                self.save_value(key_dict, value.text)\n",
    "\n",
    "    def get_data_from_horizontal_list(self):\n",
    "        web_data_list = self.get_content_by_html_tags(self.web_content, 'li')\n",
    "        for web_li in web_data_list:\n",
    "            web_data_list_div = self.get_content_by_html_tags(web_li, 'div')\n",
    "            if len(web_data_list_div)==2:\n",
    "                key_dict = self.attributes_dictionary.translate_attribute(web_data_list_div[0].text)\n",
    "                if(key_dict):\n",
    "                    self.save_value(key_dict, web_data_list_div[1].text)\n",
    "\n",
    "    def aux_add_2_dataframe(self, auction_key, auction_value, tl_ini=6):\n",
    "        self.df_auction_row[auction_key] = auction_value\n",
    "\n",
    "    def add_2_dataframe(self, tl_ini=5):\n",
    "        dict_data = self.auction_data\n",
    "        [self.aux_add_2_dataframe(auction_key, auction_value) \n",
    "            for auction_key, auction_value \n",
    "            in zip(dict_data.keys(), dict_data.values()) ]\n",
    "    \n",
    "    def get_auction_data(self, tl_ini=2): \n",
    "        self.get_description_from_auction()\n",
    "        try:\n",
    "            self.get_data_from_horizontal_table()\n",
    "        except IndexError:\n",
    "            self.get_data_from_horizontal_list()\n",
    "        self.add_2_dataframe()\n",
    "\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### get all deep data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_row_index = 4001\n",
    "max_row_index = 6000\n",
    "\n",
    "df_auctions_table = pd.read_excel(r'../auctions_download/AuctionsV2.xlsx', index_col=0)\n",
    "\n",
    "def get_all_deep_data():\n",
    "    for row_index, df_auction_row in df_auctions_table.iterrows():\n",
    "        if(min_row_index <= row_index and row_index <= max_row_index):\n",
    "            verbosity(f\"Loading data from: {df_auction_row['Country']} {df_auction_row['Year']}\", level='notif', tl=1)\n",
    "            verbosity(f\"Index: {row_index}\", level='notif', tl=1)\n",
    "            deep_auction_page = DeepAuctionPage(df_auction_row)\n",
    "            if(deep_auction_page.web_content!=False and not(deep_auction_page.found_404)):\n",
    "                deep_auction_page.get_auction_data(df_auction_row)\n",
    "                df_auctions_table.iloc[row_index] = df_auction_row\n",
    "\n",
    "get_all_deep_data()\n",
    "df_auctions_table.to_excel(\"../auctions_download/AuctionsV2.xlsx\", engine='xlsxwriter')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_auctions_table.to_excel(\"../auctions_download/AuctionsV2.xlsx\", engine='xlsxwriter')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save_operations = SaveOperations()\n",
    "# save_operations.save_html_page(html_code=str(web_content_auction_page), file_name='html_code_auction_page.html')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
