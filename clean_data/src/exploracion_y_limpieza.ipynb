{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Table of contents**<a id='toc0_'></a>    \n",
    "- [Tabla de contenido](#toc1_)    \n",
    "- [Dataset clean](#toc2_)    \n",
    "  - [Generic functions](#toc2_1_)    \n",
    "  - [load file](#toc2_2_)    \n",
    "  - [remove all totals rows](#toc2_3_)    \n",
    "  - [clean farm size](#toc2_4_)    \n",
    "  - [Generic functions](#toc2_5_)    \n",
    "- [Clean numeric data](#toc3_)    \n",
    "  - [clean score lots in table](#toc3_1_)    \n",
    "  - [clean Total Value](#toc3_2_)    \n",
    "  - [clean weight in table](#toc3_3_)    \n",
    "  - [clean Size 30Kg boxes](#toc3_4_)    \n",
    "  - [clean high bid in table](#toc3_5_)    \n",
    "  - [clean Total Comission](#toc3_6_)    \n",
    "  - [clean Altitude](#toc3_7_)    \n",
    "  - [clean growing area](#toc3_8_)    \n",
    "  - [Clean Auction Lot Size](#toc3_9_)    \n",
    "  - [Clean Auction Lot Size (Kg)](#toc3_10_)    \n",
    "  - [complete weight Lb](#toc3_11_)    \n",
    "  - [detect abnormal data](#toc3_12_)    \n",
    "- [Clean non-numeric data](#toc4_)    \n",
    "  - [Generic string functions](#toc4_1_)    \n",
    "  - [clean country](#toc4_2_)    \n",
    "  - [clean Rank](#toc4_3_)    \n",
    "  - [Clean Farmer](#toc4_4_)    \n",
    "  - [Clean Region](#toc4_5_)    \n",
    "  - [Clean Variety](#toc4_6_)    \n",
    "  - [Clean Processing](#toc4_7_)    \n",
    "  - [Clean History](#toc4_8_)    \n",
    "  - [Clean Company Name](#toc4_9_)    \n",
    "  - [Clean COMPANY NAME](#toc4_10_)    \n",
    "  - [Clean Aroma_Flavor](#toc4_11_)    \n",
    "  - [Clean Acidity](#toc4_12_)    \n",
    "  - [Clean Overall](#toc4_13_)    \n",
    "  - [Clean Other](#toc4_14_)    \n",
    "  - [Clean City](#toc4_15_)    \n",
    "  - [Remove empty rows, by col](#toc4_16_)    \n",
    "- [Convert to future value](#toc5_)    \n",
    "  - [Generic functions](#toc5_1_)    \n",
    "  - [future value converision](#toc5_2_)    \n",
    "- [save all data](#toc6_)    \n",
    "\n",
    "<!-- vscode-jupyter-toc-config\n",
    "\tnumbering=false\n",
    "\tanchor=true\n",
    "\tflat=false\n",
    "\tminLevel=1\n",
    "\tmaxLevel=6\n",
    "\t/vscode-jupyter-toc-config -->\n",
    "<!-- THIS CELL WILL BE REPLACED ON TOC UPDATE. DO NOT WRITE YOUR TEXT IN THIS CELL -->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <a id='toc1_'></a>[Tabla de contenido](#toc0_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <a id='toc2_'></a>[Dataset clean](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a id='toc2_1_'></a>[Generic functions](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def verbosity(msj, is_verbosity):\n",
    "  if is_verbosity:\n",
    "    print(msj)\n",
    "\n",
    "def search_str_in_df(df_link, df_col, str_):\n",
    "  return [(link, farm_size) for farm_size, link in zip(df_col, df_link) if type(farm_size)==str and str_ in farm_size]\n",
    "\n",
    "def load_df_from_csv(file_path):\n",
    "    try:\n",
    "        df_ipc = pd.read_csv(file_path)\n",
    "        return df_ipc\n",
    "    except FileNotFoundError:\n",
    "        print(f\"Error: File not found at {file_path}\")\n",
    "        return False\n",
    "    \n",
    "def get_ipc_older_than_value(year, df_ipc):\n",
    "    if type(year)!=float:\n",
    "        year = float(year)\n",
    "    return df_ipc[df_ipc['year']>=year]['ipc']\n",
    "\n",
    "def future_value_convertion(present_value, array_interests):\n",
    "    future_value = present_value \n",
    "    [future_value:=(future_value*(1+(interest/100))) for interest in array_interests]\n",
    "    return future_value\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a id='toc2_2_'></a>[load file](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "file_path = '../data/Auctionsv2.2.xlsx'\n",
    "\n",
    "try:\n",
    "  global df\n",
    "  df = pd.read_excel(file_path)\n",
    "except FileNotFoundError:\n",
    "  print(f\"Error: File not found at {file_path}\")\n",
    "except Exception as e:\n",
    "  print(f\"An error occurred: {e}\")\n",
    "\n",
    "\n",
    "df_ipc = load_df_from_csv('../data/inflacion_EEUU.csv')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 251
    },
    "id": "4lPh1grAXLFy",
    "outputId": "4dd7d0b6-c761-4f5d-c505-d8b157cb31e2"
   },
   "outputs": [],
   "source": [
    "df.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 300
    },
    "id": "8dwg8u3MXP6t",
    "outputId": "7e125408-e8bc-4e12-9a03-7560e06c5b6d"
   },
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 930
    },
    "id": "QNFSZ8I8XS7X",
    "outputId": "3122ea0e-05ac-411a-ae17-2716fd577b6e"
   },
   "outputs": [],
   "source": [
    "# Order values counts by year\n",
    "df['Year'].value_counts().sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 489
    },
    "id": "_nbZNnIlYma7",
    "outputId": "1ea85c60-43cb-4211-e289-dc559097b59f"
   },
   "outputs": [],
   "source": [
    "df['Country'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 742
    },
    "id": "b4Ray4BfY9hW",
    "outputId": "221346ef-7f8e-4c4f-8dbb-b27adb16166c"
   },
   "outputs": [],
   "source": [
    "\n",
    "df['Farm_Size'].value_counts().head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_t1G-beFZS9J"
   },
   "outputs": [],
   "source": [
    "# Remove \"ha\" from the 'Farm_Size' column\n",
    "df['Farm_Size'] = df['Farm_Size'].str.replace('ha', '', case=False, regex=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1W_v5oEcaAUy"
   },
   "outputs": [],
   "source": [
    "# df[df['Farm_Size'].str.contains(\"hectares\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KdIpguUBx9j7"
   },
   "outputs": [],
   "source": [
    "df['Farm_Size'] = df['Farm_Size'].str.replace('hectares farm in production', '', case=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wSZAeInyauQx"
   },
   "outputs": [],
   "source": [
    "df['Farm_Size'] = df['Farm_Size'].str.replace('-?hec.*', '', case=False, regex=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[[4678, 4675]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a id='toc2_3_'></a>[remove all totals rows](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def remove_rows_if_condition(condition, index_):\n",
    "    global df\n",
    "    if condition:\n",
    "        print(f\"drop {index_} row\")\n",
    "        df.drop(index=index_, inplace=True)\n",
    "\n",
    "[remove_rows_if_condition((\"totals:\" in str(value_) or \"total\" in str(value_) or \"stat\" in str(value_)), index_) for value_, index_ in zip(df['Rank'], df.index)]\n",
    "df.reset_index(drop=True, inplace=True)\n",
    "df.drop(columns=['Unnamed: 0'], inplace=True)\n",
    "\n",
    "\n",
    "[remove_rows_if_condition(pd.isna(value_), index_) for value_, index_ in zip(df['Rank'], df.index)]\n",
    "df.reset_index(drop=True, inplace=True)\n",
    "# df.drop(columns=['Unnamed: 0'], inplace=True)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a id='toc2_4_'></a>[clean farm size](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "is_verbosity = False\n",
    "\n",
    "# Function to clean and convert farm size\n",
    "def clean_farm_size(link, size, index_):\n",
    "  if size == \"-\":\n",
    "    size = None\n",
    "\n",
    "  if pd.isna(size):\n",
    "      return size  # Return NaN values as they are\n",
    "\n",
    "  size = str(size)\n",
    "  \n",
    "  if size == '.':\n",
    "    return None\n",
    "  \n",
    "  if '()' in size:\n",
    "    size = size.replace('()', '')\n",
    "  if ' .' in size:\n",
    "    size = size.replace(' .', '')\n",
    "\n",
    "  if '/' in size:\n",
    "    size = size.split('/')[1]\n",
    "  \n",
    "  if \"m2\" in size or \"m²\" in size or \"metros cuadrados\" in size:\n",
    "    size = size.replace(\"m2\", \"\").replace(\"m²\", \"\").replace(\"metros cuadrados\", \"\")\n",
    "    aux_size = size\n",
    "    size = size.replace(\",\", \".\")\n",
    "    verbosity(f\"size m2 = {size}\", is_verbosity)\n",
    "\n",
    "    try:\n",
    "      if float(size) <100:\n",
    "        size = aux_size.replace(\",\", \"\")\n",
    "\n",
    "      verbosity(f\"Successfull changed size to ha = {float(size) / 10000}\", is_verbosity)\n",
    "      return float(size) / 10000\n",
    "    except ValueError:\n",
    "      verbosity(f\"Error: {ValueError} in size: {size}\", is_verbosity)\n",
    "      return size # Return original string if conversion fails.\n",
    "  \n",
    "  if \"acres\" in size:\n",
    "    size = size.replace(\"acres\", \"\")\n",
    "    aux_size = size\n",
    "    size = size.replace(\",\", \".\")\n",
    "    verbosity(f\"size acres = {size}\", is_verbosity)\n",
    "\n",
    "    try:\n",
    "      verbosity(f\"Successfull changed size to ha = {float(size) * 0.404686}\", is_verbosity)\n",
    "      return float(size) * 0.404686\n",
    "    except ValueError:\n",
    "      verbosity(f\"Error: {ValueError} in size: {size}\", is_verbosity)\n",
    "      return size # Return original string if conversion fails.\n",
    "\n",
    "  if \"patok\" in size:\n",
    "    size = size.replace(\"patok\", \"\")\n",
    "    aux_size = size\n",
    "    size = size.replace(\",\", \".\")\n",
    "    verbosity(f\"size patok = {size}\", is_verbosity)\n",
    "\n",
    "    try:\n",
    "      verbosity(f\"Successfull changed size to ha = {float(size) * 0.1}\", is_verbosity)\n",
    "      return float(size) * 0.1\n",
    "    except ValueError:\n",
    "      verbosity(f\"Error: {ValueError} in size: {size}\", is_verbosity)\n",
    "      return size # Return original string if conversion fails.\n",
    "    \n",
    "  \n",
    "\n",
    "  if \"MANZANAS\" in size or \"mzns\" in size or \"manzanas\" in size or \"mz\" in size:\n",
    "    size = size.replace(\"manzanas\", \"\").replace(\"mzns\", \"\").replace(\"MANZANAS\", \"\").replace(\",\", \"\").replace(\"mz\", \"\")\n",
    "    verbosity(f\"size mzn = {size}\", is_verbosity)\n",
    "    try:\n",
    "      verbosity(f\"Successfull changed size to ha = {float(size) * 0.698896}\", is_verbosity)\n",
    "      return float(size) * 0.698896\n",
    "    except ValueError:\n",
    "      if \"y media\" in size:\n",
    "        size = size.replace(\"y media\", \"\")\n",
    "        try:\n",
    "          verbosity(f\"Successfull changed size to ha = {(float(size)+0.5) * 0.698896}\", is_verbosity)\n",
    "          return (float(size)+0.5) * 0.698896\n",
    "        except ValueError as e:\n",
    "          verbosity(f\"Error: {e} in size: {size}\", is_verbosity)\n",
    "          return size # Return original string if conversion fails.\n",
    "      verbosity(f\"Error: {ValueError} in size: {size}\", is_verbosity)\n",
    "      return size # Return original string if conversion fails.\n",
    "\n",
    "  try:\n",
    "    float(size)\n",
    "  except ValueError as e:\n",
    "    if \",\" in size:\n",
    "      try:\n",
    "        size = size.replace(\",\", \".\")\n",
    "        return size\n",
    "      except:\n",
    "        print(f\"Error: {e} in size: {size}\")\n",
    "        return size\n",
    "\n",
    "    print(f\"Second Error: {e} in size: {size}, index: {index_}, link {link}\")\n",
    "    return size\n",
    "\n",
    "  return size\n",
    "\n",
    "# [(link, value_) for value_, link in zip(df_col, df_link) if not(pd.isna(value_)) and type(float(value_))==float]\n",
    "# Apply the function to the 'Farm_Size' column\n",
    "\n",
    "df['Farm_size_he'] = pd.DataFrame( [clean_farm_size(link, value_, index_) for value_, link, index_ in zip(df['Farm_Size'], df['Url_farm'], df.index)])\n",
    "# df['farm_size_he'] = df['Farm_Size'].apply(clean_farm_size, link=df['Url_farm'])\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe(include='all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 654
    },
    "id": "y9oHcml5AqMB",
    "outputId": "92e5dcf6-2c37-4b65-d7ab-2866a0200a24"
   },
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 317
    },
    "id": "f3J6PZiaclqf",
    "outputId": "1f1fde31-204f-42b8-a778-ad5fdd5fa249"
   },
   "outputs": [],
   "source": [
    "def val_float_in_df(df_link, df_col):\n",
    "  return [(link, value_) for value_, link in zip(df_col, df_link) if not(pd.isna(value_)) and type(float(value_))==float]\n",
    "search_str_in_df(df['Url_farm'], df['Farm_size_he'], \"m\")\n",
    "# val_float_in_df(df['Url_farm'], df['Farm_size_he'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9VglNQUIyFtw"
   },
   "outputs": [],
   "source": [
    "df.to_excel('../data/AuctionsV4.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TjiB3TSncoWR"
   },
   "outputs": [],
   "source": [
    "#Revisar caso row 4301\n",
    "df.loc[[4289, 4298,4301]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a id='toc2_5_'></a>[Generic functions](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def is_float_data_detection(link, value_, index_, verbosity):\n",
    "    if pd.isna(value_):\n",
    "        return True\n",
    "\n",
    "    value_ = str(value_)\n",
    "\n",
    "    try:\n",
    "        float(value_)\n",
    "        return True\n",
    "    except:\n",
    "        if verbosity:\n",
    "            print(f\"detected non float data {value_} in row {index_}; more information in {link}\")\n",
    "        return False\n",
    "\n",
    "def non_float_data_detection(col_):\n",
    "    [is_float_data_detection(link, value_, index_, True) for value_, link, index_ in zip(df[col_], df['Url_farm'], df.index)]\n",
    "\n",
    "def str_2_float(value_):\n",
    "    if pd.isna(value_):\n",
    "        return True, value_\n",
    "    try:\n",
    "        value_ = float(value_)\n",
    "        return True, value_\n",
    "    except ValueError as e:\n",
    "        print(f\"error, parsing value {value_} Error: {e}\")\n",
    "        return False, value_\n",
    "\n",
    "\n",
    "def apply_function_to_data(col_, function_):\n",
    "    global df\n",
    "    return pd.DataFrame( [function_(link, value_, index_) for value_, link, index_ in zip(df[col_], df['Url_farm'], df.index)])\n",
    "\n",
    "def count_number_of_digits(value_):\n",
    "    if type(value_) is float:\n",
    "        value_ = str(value_)\n",
    "    \n",
    "    number_of_digits = len(value_)\n",
    "    if '.' in value_:\n",
    "        number_of_digits = number_of_digits - 3\n",
    "    \n",
    "    return number_of_digits\n",
    "    \n",
    "def replace_value(value_, str_replace, replace_for):\n",
    "    if str_replace in value_:\n",
    "        value_ = value_.replace(str_replace, replace_for)\n",
    "    return value_\n",
    "\n",
    "def normalize_number(number_string):\n",
    "    # Primero, elimina las comas o puntos usados como separadores de miles\n",
    "    number_string = re.sub(r'(?<=\\d)[.,](?=\\d{3})', '', number_string)\n",
    "    # Luego, convierte las comas decimales en puntos decimales\n",
    "    number_string = number_string.replace(',', '.')\n",
    "    return number_string\n",
    "\n",
    "def detect_abnormal_commas(value_, is_float):\n",
    "    value_ = str(value_)\n",
    "    value_ = re.sub(r'(?<=\\d)[.,](?=\\d{3})', '', value_)\n",
    "    # Convierte las comas decimales en puntos decimales\n",
    "    value_ = value_.replace(',', '.')\n",
    "\n",
    "    is_float, value_ = str_2_float(value_)\n",
    "\n",
    "    return is_float, value_\n",
    "\n",
    "def detect_range(value_):\n",
    "    patron = re.compile('\\d{1,4}.*?[–a-].*?\\d{1,4}')\n",
    "    result = patron.search(value_)\n",
    "\n",
    "    if result:\n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    "    \n",
    "    \n",
    "def get_average_from_range(value_):\n",
    "    is_feet = False\n",
    "    if 'feet' in value_:\n",
    "        is_feet = True\n",
    "    patron = re.compile('\\d{1,3},\\d\\d\\d')\n",
    "    result = patron.search(value_)\n",
    "    if(result):\n",
    "        value_ = value_.replace(',', '')\n",
    "    patron = re.compile('\\d{1,3}.\\d\\d\\d')\n",
    "    result = patron.search(value_)\n",
    "    if(result):\n",
    "        value_ = value_.replace('.', '')\n",
    "\n",
    "    patron = re.compile('\\d{1,4}')\n",
    "    result = patron.findall(value_)\n",
    "    sum=0\n",
    "    [sum:=sum+float(val) for val in result]\n",
    "    value_ = sum/len(result)\n",
    "    if is_feet:\n",
    "        value_ = value_ * 0.3048\n",
    "    is_float = True\n",
    "    return is_float, value_\n",
    "\n",
    "def units_conversion(value_, conversion_to_multiplly, unit):\n",
    "    aux_value = value_\n",
    "    value_ = value_.replace(unit, '')\n",
    "    is_float=False\n",
    "    is_float, value_ = detect_abnormal_commas(value_, is_float)\n",
    "\n",
    "    try:\n",
    "        value_ = float(value_)\n",
    "        value_ = (value_ * conversion_to_multiplly)\n",
    "        # print(f\"se convirtió el valor: {aux_value}  a {value_} exitosamente\")\n",
    "        return True, value_\n",
    "    except ValueError:\n",
    "        print(f\"No se pudo convertir {value_} a {unit} exitosamente\")\n",
    "        return True, value_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def normalize_number(number_string):\n",
    "    # Elimina las comas o puntos usados como separadores de miles\n",
    "    number_string = re.sub(r'(?<=\\d)[.,](?=\\d{3})', '', number_string)\n",
    "    # Convierte las comas decimales en puntos decimales\n",
    "    number_string = number_string.replace(',', '.')\n",
    "\n",
    "    number_string = float(number_string)\n",
    "    return number_string\n",
    "\n",
    "# Ejemplo de uso\n",
    "values = [\"1,000.20\", \"1000,20\", \"1.000,20\", \"1000,\", \"1000.\"]\n",
    "normalized_values = [normalize_number(value) for value in values]\n",
    "print(normalized_values)  # ['1000.20', '1000.20', '1000.20']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <a id='toc3_'></a>[Clean numeric data](#toc0_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a id='toc3_1_'></a>[clean score lots in table](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_score_lots(link, value_, index_):\n",
    "    is_float = False\n",
    "    value_ = str(value_)\n",
    "    if (not(is_float) and (',' in value_)):\n",
    "        value_ = value_.replace(',', '.')\n",
    "        is_float, value_ = str_2_float(value_)   \n",
    "    \n",
    "    is_float = is_float_data_detection(link, value_, index_, False)\n",
    "    if is_float:\n",
    "        return  float(value_)\n",
    "    else:\n",
    "        print(f\"detected not float data {value_} in row {index_}; more information in {link}\")\n",
    "        return value_\n",
    "\n",
    "\n",
    "df['Score_v2'] = apply_function_to_data('Score', clean_score_lots)\n",
    "# non_float_data_detection('Score_v2')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a id='toc3_2_'></a>[clean Total Value](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_total_value(link, value_, index_):\n",
    "    global df\n",
    "    value_ = str(value_)\n",
    "    aux_value_2 = value_\n",
    "    value_ = replace_value(value_, '$', '')\n",
    "    value_ = replace_value(value_, '/lb', '')\n",
    "    value_ = replace_value(value_, '/Ib', '')\n",
    "    value_ = replace_value(value_, 'US', '')\n",
    "    value_ = replace_value(value_, '.              ', '')\n",
    "\n",
    "    is_float = is_float_data_detection(link, value_, index_, False)\n",
    "    \n",
    "    if is_float:\n",
    "        return  float(value_)\n",
    "    \n",
    "    if ('-' in value_) and (not(is_float)):\n",
    "        value_ = None\n",
    "        return value_\n",
    "    if ('–' in value_) and (not(is_float)):\n",
    "        value_ = None\n",
    "        return value_\n",
    "    \n",
    "    is_float, value_ = detect_abnormal_commas(value_, is_float)\n",
    "\n",
    "    if is_float:\n",
    "        if count_number_of_digits(value_) > 3:\n",
    "            # TODO: divide high_bid / weight lb\n",
    "            # print(f\"detected abnormal number: weight lb: {df.loc()[index_]['Weigth_(Lb)']}; weight kg: {df.loc()[index_]['Weigth_(Kg)']};initial value: {aux_value_2}; processed value {value_} in row {index_}; more information in {link}\")\n",
    "            pass\n",
    "\n",
    "        return  float(value_)\n",
    "    else:\n",
    "        print(f\"detected not float data {value_} in row {index_}; more information in {link}\")\n",
    "        return value_\n",
    "\n",
    "df['Total_Value_v2'] = apply_function_to_data('Total_Value', clean_total_value)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a id='toc3_3_'></a>[clean weight in table](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_weight(link, value_, index_):\n",
    "    global df\n",
    "\n",
    "    value_lb = value_\n",
    "    value_lb = str(value_lb)\n",
    "\n",
    "    value_kg = df.loc[index_]['Weigth_(Kg)']\n",
    "    value_kg = str(value_kg)\n",
    "\n",
    "\n",
    "\n",
    "    if value_lb:\n",
    "        value_lb =value_lb.replace('lbs', '')\n",
    "        is_float, value_lb = detect_abnormal_commas(value_lb, False)\n",
    "        value_ = value_lb\n",
    "    elif 'lbs' in value_kg:\n",
    "        value_kg = value_kg.replace('lbs', '')\n",
    "        is_float, value_lb = detect_abnormal_commas(value_kg, False)    \n",
    "        value_ = value_kg\n",
    "        \n",
    "    else:\n",
    "        is_float_kg, value_kg = detect_abnormal_commas(value_kg, False)\n",
    "        value_ = value_kg\n",
    "        is_float, value_ = units_conversion(value_, 2.20462, 'kg')\n",
    "    \n",
    "        \n",
    "    value_ = str(value_)\n",
    "    aux_value_2 = value_\n",
    "\n",
    "    # is_float = is_float_data_detection(link, value_, index_, False)\n",
    "    \n",
    "    if is_float:\n",
    "        return  float(value_)\n",
    "    \n",
    "    if ('-' in value_) and (not(is_float)):\n",
    "        value_ = None\n",
    "        return value_\n",
    "    \n",
    "\n",
    "    if is_float:\n",
    "        if count_number_of_digits(value_) > 4:\n",
    "            print(f\"detected abnormal number: weight lb: {df.loc()[index_]['Weigth_(Lb)']}; weight kg: {df.loc()[index_]['Weigth_(Kg)']};initial value: {aux_value_2}; processed value {value_} in row {index_}; more information in {link}\")\n",
    "            pass\n",
    "\n",
    "        return  float(value_)\n",
    "    else:\n",
    "        print(f\"detected not float data {value_} in row {index_}; more information in {link}\")\n",
    "        return value_\n",
    "\n",
    "df['Weigth_(Lb)_v2'] = apply_function_to_data('Weigth_(Lb)', clean_weight)\n",
    "# non_float_data_detection('Score_v2')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a id='toc3_4_'></a>[clean Size 30Kg boxes](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_size_30kg_boxes(link, value_, index_):\n",
    "    global df\n",
    "    value_ = str(value_)\n",
    "    aux_value_2 = value_\n",
    "    # value_ = replace_value(value_, '$', '')\n",
    "    # value_ = replace_value(value_, '/lb', '')\n",
    "    # value_ = replace_value(value_, '/Ib', '')\n",
    "    # value_ = replace_value(value_, 'US', '')\n",
    "\n",
    "    is_float = is_float_data_detection(link, value_, index_, False)\n",
    "    \n",
    "    if is_float:\n",
    "        return  float(value_)\n",
    "    \n",
    "    if ('-' in value_) and (not(is_float)):\n",
    "        value_ = None\n",
    "        return value_\n",
    "    \n",
    "    is_float, value_ = detect_abnormal_commas(value_, is_float)\n",
    "\n",
    "    if is_float:\n",
    "        if count_number_of_digits(value_) > 2:\n",
    "            # TODO: divide high_bid / weight lb\n",
    "            print(f\"SE RECOMIENDA ELIMINAR ESTAS FILAS AL FINAL detected abnormal number: Size 30Kg boxes: {df.loc()[index_]['Size_30Kg_boxes']}; weight kg: {df.loc()[index_]['Weigth_(Kg)']};initial value: {aux_value_2}; processed value {value_} in row {index_}; more information in {link}\")\n",
    "\n",
    "        return  float(value_)\n",
    "    else:\n",
    "        print(f\"detected not float data {value_} in row {index_}; more information in {link}\")\n",
    "        return value_\n",
    "\n",
    "df['Size_30Kg_boxes_v2'] = apply_function_to_data('Size_30Kg_boxes', clean_size_30kg_boxes)\n",
    "# non_float_data_detection('Score_v2')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a id='toc3_5_'></a>[clean high bid in table](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_high_bid(link, value_, index_):\n",
    "    global df\n",
    "    value_ = str(value_)\n",
    "    aux_value_2 = value_\n",
    "    value_ = replace_value(value_, '$', '')\n",
    "    value_ = replace_value(value_, '/lb', '')\n",
    "    value_ = replace_value(value_, '/Ib', '')\n",
    "    value_ = replace_value(value_, 'US', '')\n",
    "\n",
    "    is_float = is_float_data_detection(link, value_, index_, False)\n",
    "    \n",
    "    if is_float:\n",
    "        return  float(value_)\n",
    "    \n",
    "    if ('-' in value_) and (not(is_float)):\n",
    "        value_ = None\n",
    "        return value_\n",
    "    \n",
    "    is_float, value_ = detect_abnormal_commas(value_, is_float)\n",
    "\n",
    "    if is_float:\n",
    "        if count_number_of_digits(value_) > 3:\n",
    "            # TODO: divide high_bid / weight lb\n",
    "            # print(f\"detected abnormal number: weight lb: {df.loc()[index_]['Weigth_(Lb)']}; weight kg: {df.loc()[index_]['Weigth_(Kg)']};initial value: {aux_value_2}; processed value {value_} in row {index_}; more information in {link}\")\n",
    "            pass\n",
    "\n",
    "        return  float(value_)\n",
    "    else:\n",
    "        print(f\"detected not float data {value_} in row {index_}; more information in {link}\")\n",
    "        return value_\n",
    "\n",
    "df['High_Bid_v2'] = apply_function_to_data('High_Bid', clean_high_bid)\n",
    "# non_float_data_detection('Score_v2')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a id='toc3_6_'></a>[clean Total Comission](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_total_comission(link, value_, index_):\n",
    "    global df\n",
    "\n",
    "    if pd.isna(value_) or value_=='–':\n",
    "        return None\n",
    "    \n",
    "    value_ = str(value_)\n",
    "    aux_value_2 = value_\n",
    "    value_ = replace_value(value_, '(', '')\n",
    "    value_ = replace_value(value_, '$', '')\n",
    "    value_ = replace_value(value_, ')', '')\n",
    "\n",
    "    is_float = is_float_data_detection(link, value_, index_, False)\n",
    "    \n",
    "    if is_float:\n",
    "        return  float(value_)\n",
    "        \n",
    "    is_float, value_ = detect_abnormal_commas(value_, is_float)\n",
    "\n",
    "    if is_float:\n",
    "        if count_number_of_digits(value_) > 5:\n",
    "            print(f\"detected abnormal number: initial value: {aux_value_2}; processed value {value_} in row {index_}; more information in {link}\")\n",
    "\n",
    "        return  float(value_)\n",
    "    else:\n",
    "        print(f\"detected not float data ({value_}) in row {index_}; more information in {link}\")\n",
    "        return value_\n",
    "\n",
    "df['Total_Comission_v2'] = apply_function_to_data('Total_Comission', clean_total_comission)\n",
    "# non_float_data_detection('Score_v2')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a id='toc3_7_'></a>[clean Altitude](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_altitude(link, value_, index_):\n",
    "    global df\n",
    "\n",
    "    if pd.isna(value_) or value_=='–' or value_ =='-' or value_=='-1':\n",
    "        return None\n",
    "    \n",
    "\n",
    "    \n",
    "    value_ = str(value_)\n",
    "    aux_value = value_\n",
    "    value_ = replace_value(value_, 'm,m.a.s.l.', '') \n",
    "    value_ = replace_value(value_, 'caíAverage  altitude:  ', '') \n",
    "    value_ = replace_value(value_, 'METERS ABOVE SEA LEVEL', '') \n",
    "    value_ = replace_value(value_, 'm.a.s.l.', '')\n",
    "    value_ = replace_value(value_, 'a los', '-')\n",
    "    value_ = replace_value(value_, 'm.a.s.l', '')\n",
    "    value_ = replace_value(value_, 'M.A.S.L', '') \n",
    "    value_ = replace_value(value_, 'm. o. s. l.', '') \n",
    "    value_ = replace_value(value_, 'masl / ', '-')\n",
    "    value_ = replace_value(value_, 'masl', '')\n",
    "    value_ = replace_value(value_, 'Masl', '')\n",
    "    value_ = replace_value(value_, 'm,a.s.l.', '') \n",
    "    value_ = replace_value(value_, 'm. a. s. l.', '') \n",
    "    value_ = replace_value(value_, 'MASL', '') \n",
    "    value_ = replace_value(value_, 'mts', '') \n",
    "    value_ = replace_value(value_, 'meters', '') \n",
    "    value_ = replace_value(value_, 'Msnm', '') \n",
    "    value_ = replace_value(value_, 'msnm.', '') \n",
    "    value_ = replace_value(value_, 'msnm', '') \n",
    "    value_ = replace_value(value_, 'MSNM', '') \n",
    "    value_ = replace_value(value_, 'm.s.l.m.', '') \n",
    "    value_ = replace_value(value_, 'm.a.s.s.', '') \n",
    "    value_ = replace_value(value_, 'Max. altitude:', '') \n",
    "    value_ = replace_value(value_, 'm.', '') \n",
    "    value_ = replace_value(value_, 'm', '') \n",
    "    value_ = replace_value(value_, 'above sea level', '') \n",
    "    value_ = replace_value(value_, 'Min. altitude:', '-') \n",
    "    value_ = replace_value(value_, ' to ', '-') \n",
    "    \n",
    "    value_ = replace_value(value_, 'caíAverage altitude:', '')\n",
    "    # value_ = replace_value(value_, '', '')\n",
    "\n",
    "    is_float = is_float_data_detection(link, value_, index_, False)\n",
    "\n",
    "    \n",
    "    \n",
    "\n",
    "    is_range=detect_range(value_)\n",
    "    if is_range: \n",
    "        is_float, value_ = get_average_from_range(value_)\n",
    "\n",
    "    if not(is_float) and 'hectares' in value_:\n",
    "        value_ = replace_value(value_, 'hectares', '') \n",
    "        print(f\"detected abnormal unit: initial value: {aux_value}; processed value {value_} in row {index_}; more information in {link}\")\n",
    "\n",
    "    if not(is_float) and 'ha' in value_:\n",
    "        value_ = replace_value(value_, 'ha', '') \n",
    "        print(f\"detected abnormal unit: initial value: {aux_value}; processed value {value_} in row {index_}; more information in {link}\")\n",
    "        \n",
    "\n",
    "        # value_ = units_conversion(value_, 0.3048, 'hectares')\n",
    "    \n",
    "    if not(is_float) and 'Feet' in value_:\n",
    "        is_float, value_ = units_conversion(value_, 0.3048, 'Feet')\n",
    "    \n",
    "    if not(is_float) and 'feet' in value_:\n",
    "        is_float, value_ = units_conversion(value_, 0.3048, 'feet')\n",
    "    \n",
    "    if not(is_float) and 'Ft.' in value_:\n",
    "        is_float, value_ = units_conversion(value_, 0.3048, 'Ft.')\n",
    "\n",
    "    if not(is_float) and 'ft.' in value_:\n",
    "        is_float, value_ = units_conversion(value_, 0.3048, 'ft.')\n",
    "\n",
    "    if not(is_float) and 'ft' in value_:\n",
    "        is_float, value_ = units_conversion(value_, 0.3048, 'ft')\n",
    "    \n",
    "    if not(is_float) and 'FAMSL' in value_:\n",
    "        is_float, value_ = units_conversion(value_, 0.3048, 'FAMSL')\n",
    "\n",
    "    if not(is_float) and 'fasl' in value_ :\n",
    "        is_float, value_ = units_conversion(value_, 0.3048, 'fasl')\n",
    "\n",
    "    \n",
    "    \n",
    "        \n",
    "    # if not(is_float) and ''\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "    is_float, value_ = detect_abnormal_commas(value_, is_float)\n",
    "    is_float = is_float_data_detection(link, value_, index_, True)\n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "    if is_float:\n",
    "        value_ = float(value_)\n",
    "        if  value_ < 500 or value_>=2500:\n",
    "            if value_ >= 4000:\n",
    "                value_ = value_ * 0.3048\n",
    "            else:\n",
    "                print(f\"detected abnormal number: initial value: {aux_value}; processed value {value_} in row {index_}; more information in {link}\")\n",
    "\n",
    "        return  float(value_)\n",
    "    \n",
    "    if is_float:\n",
    "        return  float(value_)\n",
    "\n",
    "    else:\n",
    "        print(f\"detected not float data {aux_value} processed value: {value_} in row {index_}; more information in {link}\")\n",
    "        return value_\n",
    "\n",
    "df['Altitude_v2(masl)'] = apply_function_to_data('Altitude', clean_altitude)\n",
    "# non_float_data_detection('Score_v2')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a id='toc3_8_'></a>[clean growing area](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_growing_area(link, value_, index_):\n",
    "    is_float = False\n",
    "    value_ = str(value_)\n",
    "    value_ = replace_value(value_, 'ha', '')\n",
    "    value_ = replace_value(value_, 'Hectares', '')\n",
    "    value_ = replace_value(value_, 'hectares', '')\n",
    "    value_ = replace_value(value_, 'hectare', '')\n",
    "    value_ = replace_value(value_, 'hectars', '')\n",
    "    value_ = replace_value(value_, 'hectar', '')\n",
    "\n",
    "    is_range=detect_range(value_)\n",
    "    if is_range: \n",
    "        is_float, value_ = get_average_from_range(value_)\n",
    "\n",
    "    is_float, value_ = str_2_float(value_)\n",
    "    if not(is_float) and 'mzns' in value_:\n",
    "        is_float, value_ = units_conversion(value_, 0.698896, 'mzns')\n",
    "    if not(is_float) and 'mzn' in value_:\n",
    "        is_float, value_ = units_conversion(value_, 0.698896, 'mzn')\n",
    "    if not(is_float) and 'MANZANAS' in value_:\n",
    "        is_float, value_ = units_conversion(value_, 0.698896, 'MANZANAS')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    # is_float, value_ = detect_abnormal_commas(value_)\n",
    "    \n",
    "    is_float, value_ = str_2_float(value_)\n",
    "    if is_float:\n",
    "        return  float(value_)\n",
    "    else:\n",
    "        print(f\"detected not float data {value_} in row {index_}; more information in {link}\")\n",
    "        return value_\n",
    "\n",
    "\n",
    "df['Coffee_Growing_Area_v2'] = apply_function_to_data('Coffee_Growing_Area', clean_growing_area)\n",
    "# non_float_data_detection('Score_v2')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a id='toc3_9_'></a>[Clean Auction Lot Size](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_auction_lot_size(link, value_, index_):\n",
    "    is_float = False\n",
    "    value_ = str(value_)\n",
    "    value_ = replace_value(value_, '(split between both presidentials)', '')\n",
    "    value_ = replace_value(value_, '(split between both presidential lots)', '')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    is_float, value_ = detect_abnormal_commas(value_, is_float)\n",
    "    is_float, value_ = str_2_float(value_)\n",
    "    if is_float:\n",
    "        return  float(value_)\n",
    "    else:\n",
    "        print(f\"detected not float data {value_} in row {index_}; more information in {link}\")\n",
    "        return value_\n",
    "df['Auction_Lot_Size_v2'] = apply_function_to_data('Auction_Lot_Size', clean_auction_lot_size)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a id='toc3_10_'></a>[Clean Auction Lot Size (Kg)](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_auction_lot_size_kg(link, value_, index_):\n",
    "    is_float = False\n",
    "    value_ = str(value_)\n",
    "    value_ = replace_value(value_, '(split between both presidentials)', '')\n",
    "    value_ = replace_value(value_, '(split between both presidential lots)', '')\n",
    "\n",
    "    is_float, value_ = detect_abnormal_commas(value_, is_float)\n",
    "    is_float, value_ = str_2_float(value_)\n",
    "    \n",
    "    if is_float:\n",
    "        return  float(value_)\n",
    "    else:\n",
    "        print(f\"detected not float data {value_} in row {index_}; more information in {link}\")\n",
    "        return None\n",
    "df['Auction_Lot_Size(Kg)_v2'] = apply_function_to_data('Auction_Lot_Size(Kg)', clean_auction_lot_size_kg)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a id='toc3_11_'></a>[complete weight Lb](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def complete_weight_lb(link, value_size_30kg_boxes, index_):\n",
    "    global df\n",
    "    weight_lb = df.loc[index_]['Weigth_(Lb)_v2']\n",
    "    lot_size = df.loc[index_]['Auction_Lot_Size_v2']\n",
    "    lot_size_kg = df.loc[index_]['Auction_Lot_Size(Kg)_v2']\n",
    "\n",
    "    \n",
    "    size_30kg_boxes_is_float = is_float_data_detection(link, value_size_30kg_boxes, index_, False)\n",
    "    lot_size_is_float = is_float_data_detection(link, lot_size, index_, False)\n",
    "    lot_size_kg_is_float = is_float_data_detection(link, lot_size_kg, index_, False)\n",
    "\n",
    "    if pd.isna(weight_lb):\n",
    "        if (lot_size_is_float and (not(pd.isna(lot_size)))):\n",
    "            weight_lb =lot_size\n",
    "            print(f\"used lot size: {lot_size} to complete weight_(lb): {weight_lb} in row {index_}; more information in {link}\")\n",
    "        elif (lot_size_kg_is_float and (not(pd.isna(lot_size_kg)))):\n",
    "            weight_lb = lot_size_kg * 2.20462\n",
    "            print(f\"used lot size in kg: {lot_size_kg} to complete weight_(lb): {weight_lb} in row {index_}; more information in {link}\")\n",
    "        elif (size_30kg_boxes_is_float and not(pd.isna(value_size_30kg_boxes))):\n",
    "            weight_lb = (value_size_30kg_boxes*132.277)/2\n",
    "            print(f\"used size_30Kb boxes: {value_size_30kg_boxes} to complete weight_(lb): {weight_lb} in row {index_}; more information in {link}\")\n",
    "    \n",
    "    return weight_lb\n",
    "\n",
    "df['Weigth_(Lb)_v2'] = apply_function_to_data('Size_30Kg_boxes_v2', complete_weight_lb)\n",
    "pass\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a id='toc3_12_'></a>[detect abnormal data](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def look_for_abnormal_data(link, value_, index_):\n",
    "\n",
    "    if pd.isna(value_):\n",
    "        return\n",
    "\n",
    "    weight_lb = value_\n",
    "    high_bid = df.loc[index_]['High_Bid_v2']\n",
    "    total_value = df.loc[index_]['Total_Value_v2']\n",
    "\n",
    "    is_total_value_float, total_value = str_2_float(total_value)\n",
    "    is_high_bid_float, high_bid = str_2_float(high_bid)\n",
    "    is_weight_lb_float, weight_lb = str_2_float(weight_lb)\n",
    "\n",
    "    if (is_total_value_float and is_high_bid_float and is_weight_lb_float):\n",
    "        if( not(pd.isna(total_value)) and not(pd.isna(high_bid)) and not(pd.isna(weight_lb))):\n",
    "            aux_weight_lb = total_value/high_bid\n",
    "            aux_weight_lb = round(aux_weight_lb, 2)\n",
    "            difference = aux_weight_lb-weight_lb\n",
    "            if(difference>1):\n",
    "                print(f\"detected inconsistences in row {index_}; more information in {link}\")\n",
    "        \n",
    "\n",
    "\n",
    "apply_function_to_data('Weigth_(Lb)_v2', look_for_abnormal_data)\n",
    "pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <a id='toc4_'></a>[Clean non-numeric data](#toc0_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a id='toc4_1_'></a>[Generic string functions](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_data_from_pattern(value_, pattern):\n",
    "\n",
    "    value_ = str(value_)    \n",
    "    pattern = re.compile(pattern)\n",
    "    result = pattern.search(value_)\n",
    "    if(result):\n",
    "        value_ =value_.replace(result.group(), '')\n",
    "        return value_\n",
    "    else:\n",
    "        return value_\n",
    "    \n",
    "def search_from_pattern(value_, pattern):\n",
    "    value_ = str(value_)    \n",
    "    pattern = re.compile(pattern)\n",
    "    result = pattern.search(value_)\n",
    "    if(result):\n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    "    \n",
    "def remove_data_from_pattern(value_, pattern, count=0):\n",
    "    value = str(value_)\n",
    "    result = re.sub(pattern, '', value_)\n",
    "    if count:\n",
    "        result = re.sub(pattern, '', value_, count)\n",
    "        \n",
    "    if result:\n",
    "        return result\n",
    "    else:\n",
    "        return value_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df['Url_farm']=='https://allianceforcoffeeexcellence.org/farm-directory/87-23/']['Aroma_Flavor']\n",
    "# remove_data_from_pattern('\\n[w]  Agricafe, S.A. De C.V.\\n', r'\\[\\w\\]|^[\\s\\n]+|[\\s\\n]+$')\n",
    "# remove_data_from_pattern(', floral, honey, sugar berries, vanilla, plum,...', r',\\s*', count=1)\n",
    "remove_data_from_pattern('\"floral, \"honey, sugar berries, vanilla, plum,...\"', r'^\"|\"$')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "# Ejemplo de string\n",
    "string_con_espacios = \"\\n[w]  Rafael Gerardo Silva Esteves\\n\"\n",
    "\n",
    "# Usar expresión regular para quitar espacios y saltos de línea al inicio y al final\n",
    "string_limpio = re.sub(r'^[\\s\\n]+|[\\s\\n]+$', '', string_con_espacios)\n",
    "\n",
    "print(f\"'{string_limpio}'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a id='toc4_2_'></a>[clean country](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_country(link, value_, index_):\n",
    "\n",
    "    if pd.isna(value_):\n",
    "        return value_\n",
    "    \n",
    "    value_ = clean_data_from_pattern(value_, '-\\d\\d\\d\\d')\n",
    "    value_ = clean_data_from_pattern(value_, '\\d\\d\\d\\d-')\n",
    "    value_ = clean_data_from_pattern(value_, '-naturals')\n",
    "    value_ = clean_data_from_pattern(value_, '-january')\n",
    "    value_ = clean_data_from_pattern(value_, '-pulped')\n",
    "    value_ = clean_data_from_pattern(value_, '-north')\n",
    "    value_ = clean_data_from_pattern(value_, '-south')\n",
    "    value_ = clean_data_from_pattern(value_, '-coe')\n",
    "    value_ = clean_data_from_pattern(value_, 'best-of-')\n",
    "    \n",
    "\n",
    "    if ('-' in value_ and not(value_=='costa-rica') and not(value_=='el-salvador')):\n",
    "        print(f\"value: {value_}; processing: {df.loc[index_]['Processing']}\")\n",
    "\n",
    "    return value_\n",
    "\n",
    "\n",
    "df['Country_v2'] = apply_function_to_data('Country', clean_country)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a id='toc4_3_'></a>[clean Rank](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_rank(link, value_, index_):\n",
    "\n",
    "    if pd.isna(value_):\n",
    "        return value_\n",
    "    \n",
    "    value_ = value_.replace('a', '')\n",
    "    value_ = value_.replace('b', '')\n",
    "    value_ = value_.replace('c', '')\n",
    "    \n",
    "    return value_\n",
    "\n",
    "\n",
    "df['Rank_v2'] = apply_function_to_data('Rank', clean_rank)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a id='toc4_4_'></a>[Clean Farmer](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_farmer(link, value_, index_):\n",
    "\n",
    "    if pd.isna(value_):\n",
    "        return value_\n",
    "    \n",
    "    value_ = remove_data_from_pattern(value_, r'\\[\\w\\]|^[\\s\\n]+|[\\s\\n]+$')\n",
    "    value_ = replace_value(value_, '\"', '\\\"')\n",
    "\n",
    "    \n",
    "\n",
    "    return value_\n",
    "\n",
    "df['Farmer'] = apply_function_to_data('Farmer', clean_farmer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a id='toc4_5_'></a>[Clean Region](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_region(link, value_, index_):\n",
    "\n",
    "    if pd.isna(value_):\n",
    "        return value_\n",
    "    \n",
    "    value_ = remove_data_from_pattern(value_, r'\\[\\w\\]|^[\\s\\n]+|[\\s\\n]+$')\n",
    "    value_ = replace_value(value_, '\"', '\\\"')\n",
    "\n",
    "    \n",
    "\n",
    "    return value_\n",
    "\n",
    "df['Region_v2'] = apply_function_to_data('Region', clean_region)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a id='toc4_6_'></a>[Clean Variety](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_variety(link, value_, index_):\n",
    "\n",
    "    if pd.isna(value_):\n",
    "        return value_\n",
    "    \n",
    "    value_ = remove_data_from_pattern(value_, r'\\[\\w\\]|^[\\s\\n]+|[\\s\\n]+$')\n",
    "    value_ = replace_value(value_, '\"', '\\\"')\n",
    "\n",
    "    \n",
    "\n",
    "    return value_\n",
    "\n",
    "df['Variety_v2'] = apply_function_to_data('Variety', clean_variety)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a id='toc4_7_'></a>[Clean Processing](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_processing(link, value_, index_):\n",
    "\n",
    "    if pd.isna(value_):\n",
    "        return value_\n",
    "    \n",
    "    value_ = remove_data_from_pattern(value_, r'\\[\\w\\]|^[\\s\\n]+|[\\s\\n]+$')\n",
    "    value_ = replace_value(value_, '\"', '\\\"')\n",
    "\n",
    "    \n",
    "\n",
    "    return value_\n",
    "\n",
    "df['Processing_v2'] = apply_function_to_data('Processing', clean_processing)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a id='toc4_8_'></a>[Clean History](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_history(link, value_, index_):\n",
    "\n",
    "    if pd.isna(value_):\n",
    "        return value_\n",
    "    \n",
    "    value_ = remove_data_from_pattern(value_, r'\\[\\w\\]|^[\\s\\n]+|[\\s\\n]+$')\n",
    "    value_ = remove_data_from_pattern(value_, r'^\"|\"$')\n",
    "    value_ = replace_value(value_, '\"', '\\\"')\n",
    "\n",
    "    \n",
    "\n",
    "    return value_\n",
    "\n",
    "df['History_v2'] = apply_function_to_data('History', clean_history)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a id='toc4_9_'></a>[Clean Company Name](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clear_company_name(link, value_, index_):\n",
    "\n",
    "    if pd.isna(value_):\n",
    "        return value_\n",
    "    \n",
    "    value_ = remove_data_from_pattern(value_, r'\\[\\w\\]|^[\\s\\n]+|[\\s\\n]+$')\n",
    "    value_ = remove_data_from_pattern(value_, r'^\"|\"$')\n",
    "    value_ = replace_value(value_, '\"', '\\\"')\n",
    "\n",
    "    \n",
    "\n",
    "    return value_\n",
    "\n",
    "df['Company_Name_v2'] = apply_function_to_data('Company_Name', clear_company_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a id='toc4_10_'></a>[Clean COMPANY NAME](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clear_company_name(link, value_, index_):\n",
    "\n",
    "    if pd.isna(value_):\n",
    "        return value_\n",
    "    \n",
    "    value_ = remove_data_from_pattern(value_, r'\\[\\w\\]|^[\\s\\n]+|[\\s\\n]+$')\n",
    "    value_ = remove_data_from_pattern(value_, r'^\"|\"$')\n",
    "    value_ = replace_value(value_, '\"', '\\\"')\n",
    "\n",
    "    \n",
    "\n",
    "    return value_\n",
    "\n",
    "df['COMPANY NAME_v2'] = apply_function_to_data('COMPANY NAME', clear_company_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a id='toc4_11_'></a>[Clean Aroma_Flavor](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_aroma(link, value_, index_):\n",
    "\n",
    "    if pd.isna(value_):\n",
    "        return value_\n",
    "    \n",
    "    value_ = remove_data_from_pattern(value_, r'\\[\\w\\]|^[\\s\\n]+|[\\s\\n]+$')\n",
    "    value_ = remove_data_from_pattern(value_, r',\\s*', count=1)\n",
    "    value_ = remove_data_from_pattern(value_, r'^\"|\"$')\n",
    "    value_ = value_.replace('#NAME?', '')\n",
    "    value_ = replace_value(value_, '\"', '\\\"')\n",
    "\n",
    "    \n",
    "\n",
    "    return value_\n",
    "\n",
    "df['Aroma_Flavor_v2'] = apply_function_to_data('Aroma_Flavor', clean_aroma)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a id='toc4_12_'></a>[Clean Acidity](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_acidity(link, value_, index_):\n",
    "\n",
    "    if pd.isna(value_):\n",
    "        return value_\n",
    "    \n",
    "    value_ = remove_data_from_pattern(value_, r'\\[\\w\\]|^[\\s\\n]+|[\\s\\n]+$')\n",
    "    value_ = remove_data_from_pattern(value_, r',\\s*', count=1)\n",
    "    value_ = remove_data_from_pattern(value_, r'^\"|\"$')\n",
    "    value_ = replace_value(value_, '\"', '\\\"')\n",
    "\n",
    "    \n",
    "\n",
    "    return value_\n",
    "\n",
    "df['Acidity_v2'] = apply_function_to_data('Acidity', clean_acidity)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a id='toc4_13_'></a>[Clean Overall](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_overall(link, value_, index_):\n",
    "\n",
    "    if pd.isna(value_):\n",
    "        return value_\n",
    "    \n",
    "    value_ = remove_data_from_pattern(value_, r'\\[\\w\\]|^[\\s\\n]+|[\\s\\n]+$')\n",
    "    value_ = remove_data_from_pattern(value_, r',\\s*', count=1)\n",
    "    value_ = remove_data_from_pattern(value_, r'^\"|\"$')\n",
    "    value_ = replace_value(value_, '\"', '\\\"')\n",
    "    \n",
    "\n",
    "    return value_\n",
    "\n",
    "df['Overall_v2'] = apply_function_to_data('Overall', clean_overall)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a id='toc4_14_'></a>[Clean Other](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_other(link, value_, index_):\n",
    "\n",
    "    if pd.isna(value_):\n",
    "        return value_\n",
    "    \n",
    "    value_ = remove_data_from_pattern(value_, r'\\[\\w\\]|^[\\s\\n]+|[\\s\\n]+$')\n",
    "    value_ = remove_data_from_pattern(value_, r',\\s*', count=1)\n",
    "    value_ = remove_data_from_pattern(value_, r'^\"|\"$')\n",
    "    value_ = value_.replace('#NAME?', '')\n",
    "    value_ = replace_value(value_, '\"', '\\\"')\n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "    return value_\n",
    "\n",
    "df['Other_v2'] = apply_function_to_data('Other', clean_other)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a id='toc4_15_'></a>[Clean City](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_city(link, value_, index_):\n",
    "\n",
    "    if pd.isna(value_):\n",
    "        return value_\n",
    "    \n",
    "    value_ = remove_data_from_pattern(value_, r'\\[\\w\\]|^[\\s\\n]+|[\\s\\n]+$')\n",
    "    value_ = remove_data_from_pattern(value_, r',\\s*', count=1)\n",
    "    value_ = remove_data_from_pattern(value_, r'^\"|\"$')\n",
    "    value_ = replace_value(value_, '\"', '\\\"')\n",
    "\n",
    "    return value_\n",
    "\n",
    "df['City_v2'] = apply_function_to_data('City', clean_city)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <a id='toc4_16_'></a>[Remove empty rows, by col](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: para tomar las estadísticas, comentar este bloque\n",
    "def clean_nan_cols(nan_cols):\n",
    "    df.replace(\"\", float(\"NaN\"), inplace=True)\n",
    "    df.dropna(subset=nan_cols, how='all', inplace=True)\n",
    "\n",
    "nan_cols = ['High_Bid_v2']\n",
    "\n",
    "clean_nan_cols(nan_cols)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <a id='toc5_'></a>[Convert to future value](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vp = 4200000\n",
    "in_ = [1/100, 1.3/100, 1.6/100, 1.9/100, 2.2/100, 2.5/100]\n",
    "vf=vp\n",
    "[vf:=(vf*(1+i)) for i in in_]\n",
    "vf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a id='toc5_1_'></a>[Generic functions](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df_ipc.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a id='toc5_2_'></a>[future value converision](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "var = get_ipc_older_than_value(2020, df_ipc)\n",
    "future_value_convertion(5000, var)\n",
    "\n",
    "\n",
    "def high_bid_to_future_value_convertion(link, value_, index_):\n",
    "\n",
    "    global df\n",
    "    global df_ipc\n",
    "    initial_year = df.loc[index_]['Year']\n",
    "    if pd.isna(value_):\n",
    "        return value_\n",
    "    array_ipc_value = get_ipc_older_than_value(initial_year, df_ipc)\n",
    "    value_ = future_value_convertion(value_, array_ipc_value)\n",
    "    print(f\"initial_year {initial_year}; value: {value_}\")\n",
    "    \n",
    "    \n",
    "    \n",
    "\n",
    "    return value_\n",
    "\n",
    "df['High_Bid_Future_Value'] = apply_function_to_data('High_Bid_v2', high_bid_to_future_value_convertion)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <a id='toc6_'></a>[save all data](#toc0_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Drop repeated columns "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def drop_columns(column_name):\n",
    "    try:\n",
    "        df.drop(columns=[column_name], inplace=True)\n",
    "    except KeyError as e:\n",
    "        print(e)\n",
    "\n",
    "\n",
    "\n",
    "df.to_excel(\"../data/AuctionsV6.7.xlsx\", engine='xlsxwriter')\n",
    "\n",
    "columns_to_drop = ['Weigth_(Kg)', 'Weigth_(Lb)', 'High_Bid', 'Farm_Size', 'Score', 'Total_Value', 'Size_30Kg_boxes', 'Total_Comission', 'Altitude', \n",
    "                   'Coffee_Growing_Area', 'Auction_Lot_Size', 'Auction_Lot_Size(Kg)', 'Country', 'Region', 'Variety', 'Processing', \n",
    "                   'History', 'Aroma_Flavor', 'Acidity', 'Overall', 'Other', 'City', 'Enviromental_Care', 'Coffee_Processing_Information', 'Annual_Precipitation', 'Shade_Grown_Type', 'Water_Source', \n",
    "                   'Company_Name', 'COMPANY NAME','Annual_Production', 'Rank']\n",
    "\n",
    "\n",
    "\n",
    "[drop_columns(column_name) for column_name in columns_to_drop]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Order columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "new_order = ['Year', 'Country_v2', 'Rank_v2', 'High_Bid_v2', 'Url_farm', 'Root_url',\n",
    "             'Score_v2', 'Origin_Bidder', 'Weigth_(Lb)_v2', 'Farm',  'Farmer', 'Certifications',\n",
    "              'Aroma_Flavor_v2', 'Acidity_v2', 'Overall_v2',\n",
    "              'Altitude_v2(masl)',\n",
    "              'High_Bidders', 'Unnamed: 39',\n",
    "              'Farm_size_he', 'Total_Value_v2', \n",
    "              'Size_30Kg_boxes_v2', 'Total_Comission_v2',\n",
    "              'Coffee_Growing_Area_v2', 'Auction_Lot_Size_v2',\n",
    "              'Auction_Lot_Size(Kg)_v2', 'Region_v2',\n",
    "              'Variety_v2', 'Processing_v2', 'History_v2', 'Company_Name_v2',\n",
    "              'COMPANY NAME_v2', \n",
    "              'Other_v2', 'City_v2', 'High_Bid_Future_Value']\n",
    "\n",
    "df = df[new_order]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save table with dropped and ordered columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_excel(\"../data/AuctionsV6.8_dropped_and_order_columns.xlsx\", engine='xlsxwriter')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def normalize_number(number_string):\n",
    "    # Elimina las comas o puntos usados como separadores de miles\n",
    "    number_string = re.sub(r'(?<=\\d)[.,](?=\\d{3})', '', number_string)\n",
    "    # Convierte las comas decimales en puntos decimales\n",
    "    number_string = number_string.replace(',', '.')\n",
    "    return number_string\n",
    "\n",
    "# Ejemplo de uso\n",
    "values = [\"1,000.20\", \"1000,20\", \"1.000,20\", \"1.000.000.20\", \"10,20\", \"10.20\", '1000.20']\n",
    "normalized_values = [normalize_number(value) for value in values]\n",
    "print(normalized_values)  # ['1000.20', '1000.20', '1000.20']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Other functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.columns.tolist()\n",
    "df.columns"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
